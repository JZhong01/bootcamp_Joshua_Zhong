{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa4a35a1",
   "metadata": {},
   "source": [
    "# Stage 09 â€” Homework Notebook\n",
    "\n",
    "In this notebook, we implement 2 engineered features. First, we load in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fb49122",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dk/pzmx27fj0198nc95vcbfwgn00000gn/T/ipykernel_5702/173081280.py:15: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  df = yf.download(['NVDA','MSFT','AAPL','GOOG','AMZN'], period='3mo', interval='1d') # .reset_index()[['Date','Close']]\n",
      "[*********************100%***********************]  5 of 5 completed\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Example synthetic data (replace with your project dataset)\n",
    "# np.random.seed(0)\n",
    "# n = 100\n",
    "# df = pd.DataFrame({\n",
    "#     'income': np.random.normal(60000, 15000, n).astype(int),\n",
    "#     'monthly_spend': np.random.normal(2000, 600, n).astype(int),\n",
    "#     'credit_score': np.random.normal(680, 50, n).astype(int)\n",
    "# })\n",
    "# df.head()\n",
    "\n",
    "import yfinance as yf\n",
    "df = yf.download(['NVDA','MSFT','AAPL','GOOG','AMZN'], period='3mo', interval='1d') # .reset_index()[['Date','Close']]\n",
    "# df.columns = ['date','adj_close']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e076a6f8",
   "metadata": {},
   "source": [
    "## Feature 1: Rolling 5-day volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9b38a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date\n",
      "2025-05-23         NaN\n",
      "2025-05-27         NaN\n",
      "2025-05-28         NaN\n",
      "2025-05-29         NaN\n",
      "2025-05-30    4.274891\n",
      "                ...   \n",
      "2025-08-18    4.519893\n",
      "2025-08-19    4.991219\n",
      "2025-08-20    7.069140\n",
      "2025-08-21    6.776104\n",
      "2025-08-22    4.818718\n",
      "Name: Close_volatility_5, Length: 63, dtype: float64\n",
      "count    59.000000\n",
      "mean      4.008117\n",
      "std       2.025340\n",
      "min       1.071679\n",
      "25%       2.833903\n",
      "50%       3.445455\n",
      "75%       4.550804\n",
      "max      10.844931\n",
      "Name: Close_volatility_5, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df['Close_volatility_5'] = df[('Close', 'MSFT')].rolling(5).std()\n",
    "print(df['Close_volatility_5'])\n",
    "print(df['Close_volatility_5'].describe().T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b83969e-4c13-4a51-b87c-11572b17831a",
   "metadata": {},
   "source": [
    "Here, we took the last 5 closing prices and calculated the standard deviation. We see here that the highest rolling 5 day has a max value of 10.845 - this marks an extremely high amount of volatility in a short timespan. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a085470",
   "metadata": {},
   "source": [
    "### Rationale for Feature 1\n",
    "From our EDA, we noted that there was a lack of involvement of time as a factor as well as how there wasn't any noticeable outliers found in intraday (Close - open price) movements. We opted to explore the rolling 5-day volatility instead to account for both of those shortcomings. This allows us to explore short-term price instability better as any significant shift is more likely to take place over a longer stretch than over the course of a single day. By calculating this instead of simply one day shifts, we were able to capture a noticeable spike of $10.85 in standard deviation, which we can identify and investigate further. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b41c4af-f84c-4ca3-b4a2-18a0e0dae024",
   "metadata": {},
   "source": [
    "## Feature 2: MSFT volume trading spikes flag "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83020f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "Price            Close        High         Low        Open    Volume  \\\n",
      "Ticker            MSFT        MSFT        MSFT        MSFT      MSFT   \n",
      "Date                                                                   \n",
      "2025-06-20  476.616486  482.666537  476.087357  481.438576  37576200   \n",
      "2025-07-30  512.397644  515.103218  508.603893  514.324469  26380400   \n",
      "2025-07-31  532.624390  554.538376  531.027040  554.318706  51617300   \n",
      "\n",
      "Price      VolumeSpike  \n",
      "Ticker            MSFT  \n",
      "Date                    \n",
      "2025-06-20           1  \n",
      "2025-07-30           1  \n",
      "2025-07-31           1  \n"
     ]
    }
   ],
   "source": [
    "# Rolling mean and std\n",
    "rolling_mean = df[('Volume', 'MSFT')].rolling(window=10, min_periods=10).mean()\n",
    "rolling_std = df[('Volume', 'MSFT')].rolling(window=10, min_periods=10).std()\n",
    "\n",
    "# Calculate threshold\n",
    "threshold = rolling_mean + 2 * rolling_std\n",
    "\n",
    "# Create spike flag column\n",
    "df[('VolumeSpike', 'MSFT')] = (df[('Volume', 'MSFT')] > threshold).astype(int)\n",
    "\n",
    "print(df[('VolumeSpike','MSFT')].sum())\n",
    "\n",
    "\n",
    "msft_columns = [col for col in df.columns if col[1] == 'MSFT']\n",
    "\n",
    "# Filter the rows where the spike flag is 1, and only keep MSFT columns   #ChatGPT used here to print the table\n",
    "msft_spikes = df[df[('VolumeSpike', 'MSFT')] == 1][msft_columns]\n",
    "print(msft_spikes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0af8d81",
   "metadata": {},
   "source": [
    "### Rationale for Feature 2\n",
    "This is useful for our model because we are now able to flag when higher-than-average volumes occurred for MSFT. This is useful because volume spikes historically correlate with wider price fluctuations, so we are now able to see when these shifts occur and investigate the underlying causes further. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
